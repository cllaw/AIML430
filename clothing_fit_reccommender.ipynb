{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e57a74b",
   "metadata": {},
   "source": [
    "# Clothing Reviews and predictive sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b00bea3",
   "metadata": {},
   "source": [
    "By: Chuan Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a pre requirement to the 'pattern framework below'\n",
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47196ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.web import Twitter\n",
    "from pattern.text.en import tag\n",
    "from pattern.vector import KNN, count\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cff864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the dataset\n",
    "df = pd.read_json('./datasets/renttherunway_final_data.json')\n",
    "print(\"Total records:\", df.shape[0])\n",
    "print(\"Train\", round(df.shape[0] * 0.7))\n",
    "print(\"Test\", round(df.shape[0] * 0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93372da7",
   "metadata": {},
   "source": [
    "Do some experimentation and analysis of the bias of lower reviews to correlation of the size of dress and age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the dataset structure and values\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e463fe2",
   "metadata": {},
   "source": [
    "I have decided to focus on the relationship between size, age, body type and weight to the rating of review.\n",
    "The following sections simply process the data and generate metrics for which I will use to make assumptions on the dataset available at hand and if I think there is any obvious bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85697891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8, 10 small <= 10\n",
    "# 14 large >= 14 is large\n",
    "\n",
    "# create the analysis dict\n",
    "body_dict = {'hourglass': 0, 'straight & narrow': 0, 'athletic': 0, 'apple': 0, 'full bust': 0, \n",
    "             'petite': 0, 'pear': 0}\n",
    "size_dict = {\"large\": 0, \"medium\": 0, \"small\":0, \"xsmall\":0}\n",
    "age_dict = {\"<19\": 0, \"20-29\": 0, \"30-39\": 0, \"40-49\": 0, \"50+\": 0}\n",
    "\n",
    "all_values = {\n",
    "    '1.0': {\n",
    "        \"total\": 0,\n",
    "        \"body_type\": [copy.deepcopy(body_dict)],\n",
    "        \"age\": [copy.deepcopy(age_dict)],\n",
    "        \"size\": [copy.deepcopy(size_dict)]\n",
    "    },\n",
    "    '2.0': {\n",
    "        \"total\": 0,\n",
    "        \"body_type\": [copy.deepcopy(body_dict)],\n",
    "        \"age\": [copy.deepcopy(age_dict)],\n",
    "        \"size\": [copy.deepcopy(size_dict)]\n",
    "    },\n",
    "    '3.0': {\n",
    "        \"total\": 0,\n",
    "        \"body_type\": [copy.deepcopy(body_dict)],\n",
    "        \"age\": [copy.deepcopy(age_dict)],\n",
    "        \"size\": [copy.deepcopy(size_dict)]\n",
    "    },\n",
    "    '4.0': {\n",
    "        \"total\": 0,\n",
    "        \"body_type\": [copy.deepcopy(body_dict)],\n",
    "        \"age\": [copy.deepcopy(age_dict)],\n",
    "        \"size\": [copy.deepcopy(size_dict)]\n",
    "    },\n",
    "    '5.0': {\n",
    "        \"total\": 0,\n",
    "        \"body_type\": [copy.deepcopy(body_dict)],\n",
    "        \"age\": [copy.deepcopy(age_dict)],\n",
    "        \"size\": [copy.deepcopy(size_dict)]\n",
    "    },\n",
    "    '6.0': {\n",
    "        \"total\": 0,\n",
    "        \"body_type\": [copy.deepcopy(body_dict)],\n",
    "        \"age\": [copy.deepcopy(age_dict)],\n",
    "        \"size\": [copy.deepcopy(size_dict)]\n",
    "    },\n",
    "    '7.0': {\n",
    "        \"total\": 0,\n",
    "        \"body_type\": [copy.deepcopy(body_dict)],\n",
    "        \"age\": [copy.deepcopy(age_dict)],\n",
    "        \"size\": [copy.deepcopy(size_dict)]\n",
    "    },\n",
    "    '8.0': {\n",
    "        \"total\": 0,\n",
    "        \"body_type\": [copy.deepcopy(body_dict)],\n",
    "        \"age\": [copy.deepcopy(age_dict)],\n",
    "        \"size\": [copy.deepcopy(size_dict)]\n",
    "    },\n",
    "    '9.0': {\n",
    "        \"total\": 0,\n",
    "        \"body_type\": [copy.deepcopy(body_dict)],\n",
    "        \"age\": [copy.deepcopy(age_dict)],\n",
    "        \"size\": [copy.deepcopy(size_dict)]\n",
    "    },\n",
    "    '10.0': {\n",
    "        \"total\": 0,\n",
    "        \"body_type\": [copy.deepcopy(body_dict)],\n",
    "        \"age\": [copy.deepcopy(age_dict)],\n",
    "        \"size\": [copy.deepcopy(size_dict)]\n",
    "    },\n",
    "    'nan': {\n",
    "        \"total\": 0,\n",
    "        \"body_type\": [copy.deepcopy(body_dict)],\n",
    "        \"age\": [copy.deepcopy(age_dict)],\n",
    "        \"size\": [copy.deepcopy(size_dict)]\n",
    "    },\n",
    "}\n",
    "\n",
    "sizes_set = set()\n",
    "body_type_set = set()\n",
    "age_set = set()\n",
    "\n",
    "# print(df.head())\n",
    "for index, row in df.iterrows():\n",
    "    rating_key = str(row['rating'])\n",
    "    all_values[rating_key][\"total\"] += 1\n",
    "    \n",
    "    sizes_set.add(row[\"size\"])\n",
    "    body_type_set.add(row[\"body type\"])\n",
    "    age_set.add(row[\"age\"])\n",
    "    \n",
    "    # TODO: use single variables here to automatically populate each size\n",
    "    if row['size'] >= 14:\n",
    "        all_values[rating_key][\"size\"][0][\"large\"] += 1\n",
    "        \n",
    "    if row['size'] > 10 and row['size'] < 14:\n",
    "        all_values[rating_key][\"size\"][0][\"medium\"] += 1\n",
    "    \n",
    "    if row['size'] > 8 and row['size'] <= 10:\n",
    "        all_values[rating_key][\"size\"][0][\"small\"] += 1\n",
    "        \n",
    "    if row['size'] <= 8:\n",
    "        all_values[rating_key][\"size\"][0][\"xsmall\"] += 1\n",
    "    \n",
    "    if row['age'] <= 19.0:\n",
    "        all_values[rating_key][\"age\"][0][\"<19\"] += 1\n",
    "                \n",
    "    if row['age'] >= 20.0 and row['age'] <= 29.0:\n",
    "        all_values[rating_key][\"age\"][0][\"20-29\"] += 1\n",
    "    \n",
    "    if row['age'] >= 30.0 and row['age'] <= 39.0:\n",
    "        all_values[rating_key][\"age\"][0][\"30-39\"] += 1\n",
    "\n",
    "    if row['age'] >= 40.0 and row['age'] <= 49.0:\n",
    "        all_values[rating_key][\"age\"][0][\"40-49\"] += 1\n",
    "    \n",
    "    if row['age'] >= 50.0:\n",
    "        all_values[rating_key][\"age\"][0][\"50+\"] += 1                \n",
    "                \n",
    "    if row['body type'] == 'hourglass':\n",
    "        all_values[rating_key][\"body_type\"][0][\"hourglass\"] += 1\n",
    "        \n",
    "    if row['body type'] == 'apple':\n",
    "        all_values[rating_key][\"body_type\"][0][\"apple\"] += 1\n",
    "    \n",
    "    if row['body type'] == 'straight & narrow':\n",
    "        all_values[rating_key][\"body_type\"][0][\"straight & narrow\"] += 1\n",
    "    \n",
    "    if row['body type'] == 'athletic':\n",
    "        all_values[rating_key][\"body_type\"][0][\"athletic\"] += 1\n",
    "        \n",
    "    if row['body type'] == 'full bust':\n",
    "        all_values[rating_key][\"body_type\"][0][\"full bust\"] += 1\n",
    "    \n",
    "    if row['body type'] == 'petite':\n",
    "        all_values[rating_key][\"body_type\"][0][\"petite\"] += 1\n",
    "\n",
    "    if row['body type'] == 'pear':\n",
    "        all_values[rating_key][\"body_type\"][0][\"pear\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f61f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "total_large = 0\n",
    "total_small = 0\n",
    "total_xsmall = 0\n",
    "\n",
    "for key in all_values:\n",
    "    if all_values[key]['total'] != 0:  # remove the ratings with no reviews\n",
    "        total += all_values[key][\"total\"]\n",
    "        total_large += all_values[key][\"size\"][0][\"large\"]\n",
    "        total_small += all_values[key][\"size\"][0][\"small\"]\n",
    "        total_xsmall += all_values[key][\"size\"][0][\"xsmall\"]\n",
    "        print(f\"Size totals {key}: {all_values[key]['size'][0]}\")\n",
    "        print(f\"Age Groups {key}: {all_values[key]['age'][0]}\")\n",
    "        print(f\"Body Type totals {key}: {all_values[key]['body_type'][0]}\")\n",
    "        print(f\"Rating amount {key}: {all_values[key]['total']}\\n\")\n",
    "    \n",
    "print(f\"Total records: {total}\")\n",
    "print(f\"Total large reviews: {total_large}\")\n",
    "print(f\"Total small reviews: {total_small}\")\n",
    "print(f\"Total xsmall reviews: {total_xsmall}\")\n",
    "# print(f\"All sizes: {sizes_set}\")\n",
    "# print(f\"All body types: {body_type_set}\")\n",
    "# print(f\"All age groups: {age_set}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cba42e",
   "metadata": {},
   "source": [
    "The number of large (including xlarge) sized reviews in the dataset is 73706 (38%)\n",
    "\n",
    "The number of small (including xsmall) sized reviews in the dataset is 91126 (47%)\n",
    "\n",
    "Highlight use case of data gap for a particular group of - eg age 34, apple sized body - see the amount reviews ratings for this compared to a more normal body type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256fc6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All calculations here are for dataset evaluation\n",
    "rating_2_size_large = all_values[\"2.0\"][\"size\"][0][\"large\"]\n",
    "rating_2_size_small = all_values[\"2.0\"][\"size\"][0][\"small\"]\n",
    "rating_2_total = all_values[\"2.0\"][\"total\"]\n",
    "rating_2_hourglass_total = all_values[\"2.0\"][\"body_type\"][0][\"hourglass\"]\n",
    "\n",
    "rating_4_size_large = all_values[\"4.0\"][\"size\"][0][\"large\"]\n",
    "rating_4_size_small = all_values[\"4.0\"][\"size\"][0][\"small\"]\n",
    "rating_4_total = all_values[\"4.0\"][\"total\"]\n",
    "\n",
    "bad_rating_total = rating_2_total + rating_4_total\n",
    "\n",
    "rating_8_size_large = all_values[\"8.0\"][\"size\"][0][\"large\"]\n",
    "rating_8_size_small = all_values[\"8.0\"][\"size\"][0][\"small\"]\n",
    "rating_8_total = all_values[\"8.0\"][\"total\"]\n",
    "\n",
    "rating_10_size_large = all_values[\"10.0\"][\"size\"][0][\"large\"]\n",
    "rating_10_size_small = all_values[\"10.0\"][\"size\"][0][\"small\"]\n",
    "rating_10_total = all_values[\"10.0\"][\"total\"]\n",
    "rating_10_hourglass_total = all_values[\"10.0\"][\"body_type\"][0][\"hourglass\"]\n",
    "\n",
    "good_rating_total = rating_8_total + rating_10_total\n",
    "\n",
    "\n",
    "# specific statistics eg: large sized bad reviews\n",
    "total_size_large = 0\n",
    "total_size_small = 0\n",
    "total_size_xsmall = 0\n",
    "\n",
    "for key in all_values:\n",
    "    total_size_large += all_values[key][\"size\"][0][\"large\"] \n",
    "    total_size_small += all_values[key][\"size\"][0][\"small\"] \n",
    "    total_size_small += all_values[key][\"size\"][0][\"xsmall\"] \n",
    "\n",
    "# rating percentages - bad\n",
    "total_bad_large_reviews = all_values[\"2.0\"][\"size\"][0][\"large\"] + all_values[\"4.0\"][\"size\"][0][\"large\"] \n",
    "total_bad_small_reviews = all_values[\"2.0\"][\"size\"][0][\"small\"] + all_values[\"4.0\"][\"size\"][0][\"small\"] + all_values[\"2.0\"][\"size\"][0][\"xsmall\"] + all_values[\"4.0\"][\"size\"][0][\"xsmall\"]  \n",
    "    \n",
    "# rating percentages - good\n",
    "total_good_large_reviews = all_values[\"8.0\"][\"size\"][0][\"large\"] + all_values[\"10.0\"][\"size\"][0][\"large\"] \n",
    "total_good_small_reviews = all_values[\"8.0\"][\"size\"][0][\"small\"] + all_values[\"10.0\"][\"size\"][0][\"small\"] + all_values[\"8.0\"][\"size\"][0][\"xsmall\"] + all_values[\"10.0\"][\"size\"][0][\"xsmall\"]\n",
    "    \n",
    "# percentages of sizes\n",
    "pct_size_large_total = (total_size_large / total) * 100\n",
    "pct_size_small_total = ((total_size_small + total_size_xsmall) / total) * 100\n",
    "\n",
    "# percentages of ratings\n",
    "pct_rating_2_total = (rating_2_total / total) * 100\n",
    "pct_rating_4_total = (rating_4_total / total) * 100\n",
    "pct_rating_10_total = (rating_10_total / total) * 100\n",
    "\n",
    "pct_bad_large = (total_bad_large_reviews/bad_rating_total) * 100\n",
    "pct_good_large = (total_good_large_reviews/good_rating_total) * 100\n",
    "\n",
    "pct_bad_small = (total_bad_small_reviews/bad_rating_total) * 100\n",
    "pct_good_small = (total_good_small_reviews/good_rating_total) * 100\n",
    "\n",
    "pct_bad_rating_total = (bad_rating_total / total) * 100\n",
    "pct_good_rating_total = (good_rating_total / total) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb983a6b",
   "metadata": {},
   "source": [
    "Display display metrics here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fbd22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{pct_bad_rating_total:.2f}% of bad ratings in total ({bad_rating_total}/{total})\")\n",
    "print(f\"{pct_good_rating_total:.2f}% of good ratings in total ({good_rating_total}/{total})\\n\")\n",
    "\n",
    "# how many large sized women gave a bad review compared to small sized womemn\n",
    "\n",
    "print(f\"Bad reviews for large size: {total_bad_large_reviews}/{bad_rating_total} ({pct_bad_large:.2f}%)\")\n",
    "print(f\"Bad reviews for small size: {total_bad_small_reviews}/{bad_rating_total} ({pct_bad_small:.2f}%)\\n\")\n",
    "\n",
    "print(f\"Good reviews for large size: {total_good_large_reviews}/{good_rating_total} ({pct_good_large:.2f}%)\")\n",
    "print(f\"Good reviews for small size: {total_good_small_reviews}/{good_rating_total} ({pct_good_small:.2f}%)\\n\")\n",
    "\n",
    "print(f\"{pct_size_large_total:.2f}% of reviews are large (size 14 or greater) ({total_size_large}/{total})\")\n",
    "print(f\"{pct_size_small_total:.2f}% of reviews are small (size 10 or less) ({total_size_small}/{total})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b9086",
   "metadata": {},
   "source": [
    "Almost 40% of the dataset has a large dress size, 44% of these users had a bad experience with the dress. This shows a slight bias towards larger dress sizes being reviewed as bad comparitively to smaller sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e578ba5",
   "metadata": {},
   "source": [
    "Here I have assumed that any review with a rating of 8 or higher is positive.\n",
    "Conversely, a rating of 4 or lower is considered negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77950bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new model\n",
    "knn = KNN()\n",
    "\n",
    "# Train it to output a score based on input\n",
    "for index, row in tqdm(df[0:134781].iterrows()):\n",
    "    if row['rating'] >= 9:\n",
    "        v = tag(row['review_text'].lower())\n",
    "        # TODO see if we can add body type and age here to train the model with\n",
    "        # have a think about what we can use that for to predict...\n",
    "        v = [word for word, pos in v if pos == 'JJ'] # JJ = adjective\n",
    "        v = count(v)\n",
    "        p = \"good\"\n",
    "    elif row['rating'] <= 3:\n",
    "        v = tag(row['review_text'].lower())\n",
    "        v = [word for word, pos in v if pos == 'JJ'] # JJ = adjective\n",
    "        v = count(v)\n",
    "        p = \"bad\"\n",
    "    if v:\n",
    "        knn.train(v, type=p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2311419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new model\n",
    "knn = KNN()\n",
    "\n",
    "# Train KNN model on the train split of data. Will determine the rating based on review text\n",
    "for index, row in tqdm(df[0:134781].iterrows()):\n",
    "    if row['rating'] >= 8:\n",
    "        v = tag(row['review_text'].lower())\n",
    "        # TODO see if we can add body type and age here to train the model with\n",
    "        # have a think about what we can use that for to predict...\n",
    "        v = [word for word, pos in v if pos == 'JJ'] # JJ = adjective\n",
    "        v = count(v)\n",
    "        p = \"good\"\n",
    "    elif row['rating'] <= 4:\n",
    "        v = tag(row['review_text'].lower())\n",
    "        v = [word for word, pos in v if pos == 'JJ'] # JJ = adjective\n",
    "        v = count(v)\n",
    "        p = \"bad\"\n",
    "    if v:\n",
    "        knn.train(v, type=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd84bbc0",
   "metadata": {},
   "source": [
    "The following reviews are placed into the classifier to test how good the outputs are. So far they are looking correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb191423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test output\n",
    "print(knn.classify(\"this dress is really lovely. it's got great lines and does amazing things for your bust. however, the two slits have a kind of loin-cloth effect\"))\n",
    "print(knn.classify('uncomfortable shapeless unflattering'))\n",
    "print(knn.classify('beautiful cute dress'))\n",
    "print(knn.classify('not reccommend, this dress is unforgiving, short, lumpy, stiff and needless, its disappointing and awful.'))\n",
    "print(knn.classify('uncomfortable and unflattering'))\n",
    "print(knn.classify('I love this'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01314b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model in the test set of dataset, and validate if it is correct or now\n",
    "\n",
    "list_of_correct_good_predictions = []\n",
    "list_of_correct_bad_predictions = []\n",
    "\n",
    "# ground truths\n",
    "total_good_reviews = 0\n",
    "total_bad_reviews = 0\n",
    "\n",
    "for index, row in tqdm(df[135082:136082].iterrows()):\n",
    "    prediction = knn.classify(row['review_text'].lower())\n",
    "#     print(f\"Review has a rating of: {row['rating']}. Prediction: {prediction}\")\n",
    "    \n",
    "    if row[\"rating\"] >= 8:\n",
    "#         print(f\"Correct good predicted review {row['rating']}: {row['review_text']}\")\n",
    "        total_good_reviews += 1\n",
    "        if prediction == \"good\":\n",
    "            list_of_correct_good_predictions.append({\n",
    "                \"userid\": row['user_id'],\n",
    "                \"rating\": row['rating'],\n",
    "                \"text\": row['review_text'],\n",
    "                \"size\": row['size'],\n",
    "                \"age\": row[\"age\"]\n",
    "            })\n",
    "    \n",
    "    elif row[\"rating\"] <= 4:\n",
    "        total_bad_reviews += 1\n",
    "        if prediction == \"bad\":\n",
    "            list_of_correct_bad_predictions.append({\n",
    "                \"userid\": row['user_id'],\n",
    "                \"rating\": row['rating'],\n",
    "                \"text\": row['review_text'],\n",
    "                \"size\": row['size'],\n",
    "                \"age\": row[\"age\"]\n",
    "            })\n",
    "    \n",
    "    # Uncomment these to sample some of the predictions\n",
    "#     if prediction == \"bad\" and row[\"rating\"] >= 8:\n",
    "#         print(f\"Bad predicted review {row['rating']}: {row['review_text']}\")\n",
    "        \n",
    "#     if prediction == \"good\" and row[\"rating\"] <= 4:\n",
    "#         print(f\"Good predicted review {row['rating']}: {row['review_text']}\")\n",
    "print(\"-\" * 10)\n",
    "    \n",
    "length_correct_good_predtiction = len(list_of_correct_good_predictions)\n",
    "length_correct_bad_predtiction = len(list_of_correct_bad_predictions)\n",
    "print(f\"Total amount of correct good predictions: {length_correct_good_predtiction}/ {total_good_reviews} ({(length_correct_good_predtiction/total_good_reviews)*100:.2f}%)\")\n",
    "print(f\"Total amount of correct bad predictions: {length_correct_bad_predtiction} / {total_bad_reviews} ({(length_correct_bad_predtiction/total_bad_reviews)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cda0b94",
   "metadata": {},
   "source": [
    "500it [02:49,  2.94it/s]\n",
    "----------\n",
    "Total amount of correct good predictions: 444/ 57763 (0.7686581375621072%)\n",
    "Total amount of correct bad predictions: 0 / 57763 (0.0%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f571ca37",
   "metadata": {},
   "source": [
    "Now I want to analyse the length of good to bad rated adjectives in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c92fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate all the good reviews from the bad reviews - This takes quite a while on the whole dataset\n",
    "# for quicker computation time, I have reduced this to the first 10000 records\n",
    "# results of the full dataset are documented in the report\n",
    "\n",
    "# get a list of adjectives of the good reviews and train those to be 'Positive'\n",
    "# get a list of adjectives of the bad reviews and train those to be 'Negative'\n",
    "\n",
    "good_df = []\n",
    "bad_df = []\n",
    "\n",
    "for index, row in tqdm(df[0:10000].iterrows()):\n",
    "    if row['rating'] >= 8:\n",
    "        good_df.append(row)\n",
    "    elif row['rating'] <= 4:\n",
    "        bad_df.append(row)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "print(f\"Amount of positive reviews: {len(good_df)}\")\n",
    "print(f\"Amount of negative reviews: {len(bad_df)}\")\n",
    "good_result = pd.concat(good_df)\n",
    "bad_result = pd.concat(bad_df)\n",
    "\n",
    "# generate list of good words\n",
    "good_words = []\n",
    "bad_words = []\n",
    "\n",
    "print(\"Computing list of positive words...\")\n",
    "for item in good_result['review_text']:\n",
    "    v = tag(item)\n",
    "    v = [word for word, pos in v if pos == 'JJ']\n",
    "    v = count(v)\n",
    "    good_words += list(v.keys())\n",
    "    \n",
    "print(\"Computing list of negative words...\")\n",
    "for item in bad_result['review_text']:\n",
    "    v = tag(item)\n",
    "    v = [word for word, pos in v if pos == 'JJ']\n",
    "    v = count(v)\n",
    "    bad_words += list(v.keys())\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95279be",
   "metadata": {},
   "source": [
    "I noticed a lot of positive adjectives present in reviews rated good were also in present in bad - probably due to the combined use of these words to describe the dress. So assuming the same adjective in both good and bad reviews would 'cancel' each other out so to say, I wanted to find the number of uniquely 'bad' adjectives from the limited set of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d38b861",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_words_final = list(set(good_words))\n",
    "bad_words_final = list(set(bad_words))\n",
    "\n",
    "print(f\"Total amount of unique positive adjectives: {len(good_words_final)}\")\n",
    "print(f\"Total amount of unique negative adjectives: {len(bad_words_final)}\")\n",
    "\n",
    "bad_words_final_filtered = [i for i in bad_words_final if i not in good_words_final]\n",
    "print(f\"Total amount of negative adjectives that aren't identified in positive reviews: {len(bad_words_final_filtered)}:{bad_words_final_filtered}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
